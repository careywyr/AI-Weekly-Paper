## Seed1.5-VL Technical Report  
[Seed1.5-VL 技术报告](https://arxiv.org/abs/2505.07062)  

我们提出 Seed1.5-VL，这是一个旨在提升通用多模态理解与推理能力的视觉-语言基础模型。Seed1.5-VL 包含一个 5.32 亿参数的视觉编码器和一个 200 亿激活参数的专家混合 (Mixture-of-Experts, MoE) 大语言模型。尽管其架构较为轻量，但该模型在广泛的公共 VLM 基准测试和内部评估集中展现出卓越性能，在 60 个公共基准测试中的 38 个上取得了业界领先性能。此外，在 GUI 控制和游戏玩法等智能体任务中，Seed1.5-VL 的表现优于包括 OpenAI CUA 和 Claude 3.7 在内的主流多模态系统。除了视觉与视频理解能力外，该模型还具备强大的推理能力，使其在视觉谜题等多模态推理挑战中表现尤为突出。我们相信这些能力将支持更广泛的任务应用。本报告详细总结了我们在模型设计、数据构建及各阶段训练过程中构建 Seed1.5-VL 的经验，希望这份报告能推动相关领域的进一步研究。Seed1.5-VL 现已通过 https://www.volcengine.com/ 开放访问（火山引擎模型 ID：doubao-1-5-thinking-vision-pro-250428）。

## MiniMax-Speech: Intrinsic Zero-Shot Text-to-Speech with a Learnable Speaker Encoder
[MiniMax-Speech：具有可学习说话人编码器的原生零样本文本转语音系统](https://arxiv.org/abs/2505.07916)

本文提出MiniMax-Speech，这是一种基于自回归Transformer架构的文本转语音（TTS）模型，能够生成高质量语音。其核心创新在于可学习说话人编码器，该模块可直接从参考音频中提取音色特征而无需文本转录。这一设计使模型能够以零样本方式生成与参考音色保持一致的、具有高表现力的语音合成结果，同时支持与参考音色高度相似的单样本语音克隆。此外，通过引入Flow-VAE模块，进一步提升了合成音频的整体质量。该模型支持32种语言，在多项客观和主观评估指标中均展现出卓越性能。特别值得注意的是，该模型在语音克隆的客观指标（词错误率和说话人相似度）上达到了最先进水平（SOTA），并在公开的TTS Arena排行榜中位列第一。得益于说话人编码器提供的鲁棒且解耦的表示特征，MiniMax-Speech的另一显著优势在于其无需修改基础模型即可实现功能扩展，支持多种应用场景，包括：基于LoRA的任意语音情感控制、通过文本描述直接合成音色特征的文本到音色（T2V）转换，以及通过额外数据对音色特征进行微调的专业语音克隆（PVC）等。更多示例请访问https://minimax-ai.github.io/tts_tech_report。

## Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models
[超越“顿悟”：大推理模型的系统性元能力对齐研究](https://arxiv.org/abs/2505.10554)

大推理模型 (Large Reasoning Models, LRMs) 已内生长链推理能力。已有研究表明，基于结果的强化学习 (Reinforcement Learning, RL) 可自发触发自我修正、回溯和验证等高级推理行为，这类现象常被称为模型的“顿悟时刻”。然而，这些行为的触发时机与稳定性仍不可预测且难以控制，制约了 LRMs 推理能力的可扩展性与可靠性。为解决这一问题，我们摒弃了依赖提示词和随机“顿悟”的传统方法，转而采用自动生成且可自验证的任务，显式地将模型与三种元能力（演绎、归纳和溯因）对齐。通过三阶段流程——个体对齐、参数空间融合及领域专用强化学习，模型性能较指令微调基线提升超 10%。进一步实验表明，基于对齐检查点的领域专用强化学习，在数学、编程和科学基准测试中平均可带来 2% 的额外性能提升，证实显式元能力对齐能为推理任务提供可扩展的可靠基础。代码已开源：https://github.com/zhiyuanhubj/Meta-Ability-Alignment

## MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining
[MiMo：解锁大语言模型的推理潜能——从预训练到微调](https://arxiv.org/abs/2505.07608)

我们提出MiMo-7B，这是一个专为推理任务设计的大语言模型，在预训练和微调阶段均进行了优化。在预训练阶段，我们改进了数据预处理流程，并采用三阶段混合数据策略来增强基础模型的推理能力。MiMo-7B-Base基于25万亿token进行预训练，并采用多token预测（Multi-Token Prediction）目标函数来提升性能并加速推理。在微调阶段，我们构建了包含13万道可验证数学与编程题目的数据集用于强化学习，通过测试难度驱动的奖励机制缓解稀疏奖励问题，并采用数据重采样策略来稳定训练过程。实验结果表明，MiMo-7B-Base展现出卓越的推理能力，性能甚至超过更大的32B模型。经过强化学习微调的最终模型MiMo-7B-RL，在数学、编程和通用推理任务上均表现优异，超越了OpenAI o1-mini的性能水平。模型权重已开源在https://github.com/xiaomimimo/MiMo。

## BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset  
[BLIP3-o：完全开放的统一多模态模型家族（架构、训练与数据集）](https://arxiv.org/abs/2505.09568)  

图像理解与生成的统一框架已成为多模态模型研究的重要方向。尽管图像理解模块的设计已得到充分探索，但兼具图像生成功能的统一模型在架构设计与训练方法上仍缺乏系统性研究。基于自回归模型和扩散模型在高质量生成与可扩展性方面的显著优势，我们系统研究了这两种范式在统一多模态场景下的应用，重点分析了图像表征形式、建模目标函数和训练策略的影响。研究发现表明：采用扩散 Transformer 生成 CLIP 图像语义特征（相较于传统 VAE 表征）能同时提升训练效率和生成质量。此外，通过"先理解后生成"的渐进式预训练策略，可在保持图像理解能力的前提下有效培养生成能力。我们还利用 GPT-4o 构建了 BLIP3o-60k 指令微调数据集，其多样化标注涵盖场景、物体、人体动作等多维度内容。基于上述创新设计、验证有效的训练方法及高质量数据集，我们开发了 BLIP3-o 系列模型——一组性能领先的统一多模态模型。实验证明，BLIP3-o 在主流图像理解与生成基准测试中均达到最优水平。为促进社区发展，我们完整开源了所有资源，包括模型代码、权重、训练脚本以及预训练/指令微调数据集。

## Bielik v3 Small: Technical Report  
[Bielik v3 Small: 技术报告](https://arxiv.org/abs/2505.02550)  

本文介绍 Bielik v3 系列模型——专为波兰语处理优化的高效参数生成式文本模型（Generative Text Models，1.5B 和 4.5B 参数规模）。研究表明，经过针对性优化的轻量级架构能够以显著更低的计算成本，达到与大规模模型相当的效能。该系列模型的核心创新包括：(1) 定制波兰语分词器 APT4，显著提升 Token 编码效率；(2) 加权指令交叉熵损失（Weighted Instruction Cross-Entropy Loss），平衡不同指令类型的学习权重；(3) 动态调整的自适应学习率（Adaptive Learning Rate）。基于涵盖 3.03 亿文档、总规模达 2920 亿 Token 的精选语料库训练，模型在多项基准测试中表现卓越，包括 Open PL 大语言模型排行榜、波兰复杂文本理解基准（Complex Polish Text Understanding Benchmark）、波兰 EQ-Bench 及波兰医学评测榜（Polish Medical Leaderboard）。其中 4.5B 参数模型的性能可与 2-3 倍规模的模型竞争，而 1.5B 参数模型在超轻量级架构下仍保持优异表现。这些成果为资源受限场景下的高质量波兰语 AI 应用树立了高效参数语言建模的新标杆。

## Step1X-3D: Towards High-Fidelity and Controllable Generation of Textured 3D Assets  
[Step1X-3D：高保真可控纹理化3D资产生成](https://arxiv.org/abs/2505.07747)  

尽管生成式人工智能在文本、图像、音频和视频领域已取得显著进展，但3D生成仍因数据稀缺、算法局限及生态碎片化等核心挑战发展滞后。为此，我们提出开放框架Step1X-3D，其创新包括：(1) 通过严格数据筛选流程从500万资产中构建200万高质量数据集，具备标准化几何与纹理属性；(2) 采用混合VAE-DiT几何生成器与扩散式纹理合成模块的双阶段3D原生架构；(3) 完整开源模型、训练代码及适配模块。几何生成阶段，混合VAE-DiT组件通过Perceiver架构的潜在编码与锐边采样技术生成TSDF表示以保留细节；纹理合成模块则通过几何条件约束与潜在空间同步确保多视角一致性。基准测试显示其性能超越现有开源方案，并与商业方案质量相当。该框架独创性地实现了2D与3D生成范式的衔接，支持将2D控制技术（如LoRA）直接迁移至3D合成。通过同步提升数据质量、算法保真度与可复现性，Step1X-3D旨在为可控3D资产生成领域建立开放研究新基准。

## System Prompt Optimization with Meta-Learning
[基于元学习的系统提示优化](https://arxiv.org/abs/2505.09666)

大语言模型 (LLMs) 已展现出卓越的能力，其中输入提示的优化对性能提升至关重要。虽然 LLM 提示包含任务无关的系统提示和任务特定的用户提示，但现有研究主要集中于针对单个查询或任务的用户提示优化，而忽视了系统提示的优化潜力——经过优化的系统提示可跨任务和领域通用。基于此，我们提出了双层系统提示优化这一新问题，旨在设计具有以下特性的系统提示：(1) 对多样化用户提示具有鲁棒性；(2) 可迁移至未见任务。为此，我们开发了一个元学习框架，通过在多数据集上联合优化系统提示与迭代更新用户提示，确保二者协同优化。我们在5个不同领域的14个未见数据集上进行实验，结果表明该方法生成的系统提示能有效适应多样化用户提示。此外，优化后的系统提示展现出快速适应能力：对于未见任务，仅需少量优化步骤即可提升用户提示性能。

## Bielik 11B v2 Technical Report  
[Bielik 11B v2 技术报告](https://arxiv.org/abs/2505.02410)  

本文介绍 Bielik 11B v2——一款专为波兰语文本处理优化的前沿语言模型。该模型基于 Mistral 7B v0.2 架构，采用深度扩展技术将参数量提升至 110 亿，在波兰语基准测试中表现卓越，同时具备出色的跨语言能力。我们提出两项核心技术创新：(1) 加权指令交叉熵损失 (Weighted Instruction Cross-Entropy Loss)，通过基于样本质量的权重分配优化多类型指令学习；(2) 自适应学习率 (Adaptive Learning Rate)，可根据上下文长度动态调整。综合评估显示，Bielik 11B v2 性能超越多个参数量为其 2-6 倍的更大模型，并在语言理解至复杂推理等任务上显著优于其他波兰语专用模型。凭借参数高效性和丰富的量化选项，该模型可适配多种硬件配置，不仅推动了波兰语 AI 技术的发展，更为资源受限语言的高效建模树立了新标杆。

