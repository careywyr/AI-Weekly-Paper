## RWKV-7 "Goose" with Expressive Dynamic State Evolution
[RWKV-7 "Goose"：具备动态状态演化能力的架构](https://arxiv.org/abs/2503.14456)

本文提出 RWKV-7 "Goose"新型序列建模架构及其预训练语言模型。该模型在 30 亿参数规模下实现了多语言任务下游性能的新突破，其英语任务表现与当前最优模型相当，但训练 token 量显著少于同类 30 亿参数模型。值得注意的是，RWKV-7 模型仅需恒定内存开销和恒定时间完成每个 token 的推理。该架构创新性地提出了具有向量门控和上下文学习率的广义 delta 规则，以及宽松的值替换规则。实验证明 RWKV-7 能实现状态追踪并识别所有正则语言，同时保持训练过程的可并行性。这一特性超越了标准复杂度假设下 Transformer 的能力边界（后者仅限于 $\mathsf{TC}^0$）。为验证 RWKV-7 的语言建模能力，我们构建了包含 3.1 万亿 token 的开源多语言语料库，并基于该数据集训练了四个参数规模从 1.9 亿至 29 亿不等的 RWKV-7 模型。

为促进技术开放、成果复现和实际应用，我们在 https://huggingface.co/RWKV 公开了模型及数据集组件清单，并在 https://github.com/RWKV/RWKV-LM 开源了训练与推理代码，所有内容均采用 Apache 2.0 许可证。

## DropletVideo: A Dataset and Approach to Explore Integral Spatio-Temporal Consistent Video Generation
[DropletVideo：探索时空一致性视频生成的数据集与方法](https://arxiv.org/abs/2503.06053)  

时空一致性是视频生成领域的核心研究问题。优质的生成视频需要同时满足情节逻辑连贯性，以及在不同视角下保持物体与场景的视觉一致性。现有研究（尤其是开源项目）往往仅关注时间或空间单一维度的连续性，或进行简单叠加处理，例如在提示词后添加相机运动描述却不对运动结果施加约束。然而，相机运动可能导致场景中物体新增或消失，进而干扰原有叙事逻辑。当视频包含频繁的相机运动时，多情节间的交互关系会变得尤为复杂。本文提出并研究了整体时空一致性机制，重点分析情节推进与拍摄技术的协同关系，以及历史内容对后续生成的持续性影响。研究工作包含完整的实现链路：首先构建了包含1000万条视频的DropletVideo-10M数据集，每条视频均包含动态相机运动和物体动作，并配有平均206个单词的详细标注，描述相机运动轨迹与情节演进；随后开发了DropletVideo模型，该模型在视频生成过程中能有效保持时空连贯性。项目资源详见https://dropletx.github.io。

## ReCamMaster: Camera-Controlled Generative Rendering from A Single Video
[ReCamMaster：基于单视频的相机控制生成式渲染](https://arxiv.org/abs/2503.11647)

在文本或图像条件视频生成领域，相机控制技术已得到广泛研究。然而，修改给定视频的相机轨迹这一方向仍存在探索不足的问题，尽管该技术在视频创作中具有重要意义。该任务的难点在于需要同时满足多帧外观一致性和动态同步的约束条件。为此，我们提出ReCamMaster框架——一种支持相机轨迹编辑的生成式视频重渲染系统，可在新视角下重建输入视频的动态场景。其核心创新在于通过简洁高效的视频条件机制，深度挖掘预训练文本到视频(text-to-video)模型的生成潜力（当前研究常忽视这一特性）。针对高质量训练数据稀缺的难题，我们基于Unreal Engine 5构建了专业的多相机同步视频数据集，该数据集经过精细设计以符合真实拍摄特征，覆盖多样化场景与相机运动模式，有效提升了模型对野外视频(in-the-wild)的泛化能力。此外，通过精心设计的训练策略进一步增强了模型对异构输入的鲁棒性。大量实验表明，本方法在性能上显著超越现有最优方法和强基线系统，并在视频稳定、超分辨率和画面扩展等任务中展现出应用价值。项目页面：
https://jianhongbai.github.io/ReCamMaster/

## DAPO: An Open-Source LLM Reinforcement Learning System at Scale
[DAPO：开源的大规模大语言模型强化学习系统](https://arxiv.org/abs/2503.14476)

通过扩展推理规模，大语言模型获得了前所未有的推理能力，而强化学习是实现复杂推理的核心技术。然而，当前最先进推理大语言模型的关键技术细节（如 OpenAI o1 博客和 DeepSeek R1 技术报告所述）并未公开，导致研究社区难以复现其强化学习训练结果。我们提出了解耦裁剪动态采样策略优化 ($\textbf{DAPO}$) 算法，并完整开源了基于 Qwen2.5-32B 基础模型的先进大规模强化学习系统，该系统在 AIME 2024 上取得了 50 分的成绩。不同于以往隐瞒训练细节的研究，我们详细介绍了实现大规模大语言模型强化学习成功的四项关键技术。此外，我们开源了基于 verl 框架的训练代码，以及经过精心处理和整理的数据集。这些开源组件不仅提高了研究的可复现性，也为未来大规模大语言模型强化学习研究提供了支持。

## One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation
[基于蒸馏的单步残差偏移扩散图像超分辨率方法](https://arxiv.org/abs/2503.13358)

基于扩散模型的超分辨率(SR)技术能够生成高质量视觉结果，但面临计算成本高昂的问题。尽管已有多种加速方案，但部分方法(如SinSR)难以还原真实感知细节，另一些方法(如OSEDiff)可能产生虚假结构。为此，我们提出RSD——一种针对顶级扩散式超分辨率模型ResShift的新型蒸馏方法。该方法通过训练学生网络生成特定图像，使得基于这些图像训练的模拟ResShift模型能与教师模型保持一致性。RSD实现了单步图像恢复，其性能显著优于教师模型。实验表明，我们的蒸馏方法超越了其他ResShift蒸馏方案(如SinSR)，达到当前最先进的扩散式超分辨率蒸馏水平。与基于预训练文生图模型的超分辨率方法相比，RSD在保持同等感知质量的同时，能生成与退化输入图像对齐度更优的结果，且所需参数量和GPU显存更少。我们在RealSR、RealSet65、DRealSR、ImageNet和DIV2K等多个真实场景与合成数据集上进行了实验验证。

## PLADIS: Pushing the Limits of Attention in Diffusion Models at Inference Time by Leveraging Sparsity
[PLADIS：基于稀疏注意力优化的扩散模型推理加速方法](https://arxiv.org/abs/2503.07677)

扩散模型在采用无分类器引导 (CFG) 等技术生成高质量条件样本方面已展现出卓越性能。然而，现有方法通常需要额外训练或神经函数评估 (NFEs)，导致其无法兼容引导蒸馏 (guidance-distilled) 模型，且依赖需要手动确定目标层的启发式方法。本文提出了一种名为 PLADIS 的新型高效方法，通过利用稀疏注意力机制增强预训练模型 (U-Net/Transformer) 的性能。具体而言，我们在推理阶段使用 softmax 函数及其稀疏变体来优化交叉注意力层中的查询-键相关性计算，无需额外训练或 NFEs。借助稀疏注意力特有的噪声鲁棒性，PLADIS 成功释放了文生图扩散模型的潜在能力，使其在原有性能瓶颈领域获得了显著提升。该方法可无缝集成各类引导技术，包括引导蒸馏模型。实验结果表明，PLADIS 在文本对齐度和人类偏好度方面均有显著提升，提供了一种高效通用的解决方案。项目主页详见：https://cubeyoung.github.io/pladis-project/

## Survey on Evaluation of LLM-based Agents
[基于大语言模型的智能体评估综述](https://arxiv.org/abs/2503.16416)

基于大语言模型（LLM）的智能体的出现标志着人工智能领域的范式转变，这类自主系统能够在动态环境交互中实现规划、推理、工具使用和记忆维持。本文首次系统综述了针对这类能力持续增强的智能体的评估方法体系。我们围绕四个关键维度系统分析了相关评估基准与框架：(1) 基础能力维度（规划、工具使用、自我反思和记忆）；(2) 领域应用维度（网络、软件工程、科学研究和对话系统）；(3) 通用智能体基准；(4) 评估框架体系。研究发现当前呈现三大趋势：评估场景日趋真实化、挑战性持续升级、基准测试动态更新。同时识别出未来研究的重点方向：需建立成本效益、安全性和鲁棒性的评估体系，发展细粒度可扩展的评估方法。本综述系统勾勒了智能体评估领域的发展脉络，揭示了当前技术瓶颈，并为后续研究提供了方向性建议。

## SmolDocling: An ultra-compact vision-language model for end-to-end multi-modal document conversion
[SmolDocling：面向端到端多模态文档转换的超紧凑视觉语言模型](https://arxiv.org/abs/2503.11576)

本文提出 SmolDocling，一种专为端到端文档转换设计的超紧凑视觉语言模型。该模型通过生成新型通用标记格式 DocTags 实现全页面处理，能够完整记录所有页面元素及其上下文信息和位置坐标。与现有方案相比，SmolDocling 摒弃了依赖大型基础模型或多专业模型拼接的复杂流程，仅用 2.56 亿参数的视觉语言模型即可实现端到端转换，精确提取文档元素的内容、结构和空间位置信息。实验表明，该模型在代码片段、表格、公式、图表、列表等文档特征的还原任务中表现优异，支持商业文档、学术论文、技术报告、专利及表单等多种文档类型，突破了现有方法主要针对科研论文的局限性。我们还开源了针对图表、表格、公式和代码识别的新数据集。测试结果显示，SmolDocling 的性能可与参数量达 27 倍的视觉语言模型相媲美，同时显著降低计算开销。模型已开放使用，数据集即将公开。

## Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models
[大语言模型高效推理方法综述](https://arxiv.org/abs/2503.16419)

大语言模型（LLMs, Large Language Models）在复杂任务中展现出卓越能力。近期大推理模型（LRMs, Large Reasoning Models）如OpenAI o1和DeepSeek-R1的突破，通过监督微调（SFT, Supervised Fine-Tuning）和强化学习（RL, Reinforcement Learning）技术增强思维链（CoT, Chain-of-Thought）推理，显著提升了在数学和编程等系统2型推理（System-2 reasoning）领域的性能。然而，更长的CoT推理序列虽能提升性能，却因输出冗长冗余而产生显著计算开销，这种现象被称为"过度思考现象（overthinking phenomenon）"。本文首次系统性地综述了大语言模型高效推理的研究进展。基于LLMs的固有机制，我们将现有工作分类为以下关键方向：(1) 模型导向的高效推理：通过优化全长度推理模型或直接训练高效推理模型；(2) 输出导向的高效推理：在推理过程中动态减少推理步骤和长度；(3) 输入导向的高效推理：通过控制输入提示（prompt）的难度或长度等属性提升效率。此外，我们还探讨了高效训练数据的使用、小语言模型的推理能力，以及评估方法和基准测试体系。

## Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills
[Being-0：基于视觉-语言模型与模块化技能的人形机器人智能体](https://arxiv.org/abs/2503.12533)

开发具备现实世界具身任务人类水平执行能力的自主机器人智能体是人形机器人研究的终极目标。当前，基础模型（FMs）在高层认知方面的突破与人形机器人底层技能的开发均已取得显著进展。然而，若直接整合这些组件，会因长时程任务中的误差累积及各模块的延迟差异而导致系统鲁棒性和执行效率下降。本文提出Being-0分层智能体框架，通过融合基础模型与模块化技能库：基础模型负责指令理解、任务规划与推理等高层认知功能；技能库则实现稳定的运动控制与灵巧操作等底层能力。为衔接这两个层级，我们创新性地采用轻量级视觉-语言模型（VLM）驱动的Connector模块，该模块能够将语言描述的任务规划转化为可执行技能指令，并通过动态协调运动与操作来提升任务完成率，从而强化基础模型的具身能力。除基础模型外，所有组件均可部署于低成本嵌入式计算设备，使得配备灵巧手与主动视觉系统的全尺寸人形机器人Being-0能够实现高效实时运行。在大型室内环境中的大量实验表明，Being-0能有效完成需要复杂导航与操作子任务的长时程任务。更多技术细节与演示视频请访问：https://beingbeyond.github.io/being-0。

## Impossible Videos
[不可能视频](https://arxiv.org/abs/2503.14378)

当前，合成视频被广泛用于弥补真实世界视频数据的稀缺性和多样性。现有合成数据集主要复制真实世界场景，而对不可能、反事实和反现实等视频概念的探索仍不充分。本研究旨在回答两个核心问题：1) 当前视频生成模型能否有效遵循提示生成不可能视频内容？2) 当前视频理解模型是否具备足够能力理解不可能视频？为此，我们提出了IPV-Bench这一新型基准测试，旨在评估并推动视频理解与生成技术的发展。IPV-Bench基于一套涵盖4个领域、14个类别的完整分类体系，包含大量违背物理、生物、地理或社会法则的多样化场景。基于该分类体系，我们构建了提示词集合来评估视频生成模型在遵循提示和创造性方面的能力。此外，我们还筛选了视频测试集来评估视频大语言模型理解不可能视频的能力，这特别需要模型具备时序动态推理和世界知识。全面评估揭示了当前视频模型的局限性，为未来发展方向提供了重要见解，为下一代视频模型的发展奠定了基础。

## φ-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation
[φ-Decoding：面向推理时探索与利用平衡的自适应前瞻采样](https://arxiv.org/abs/2503.13288)

推理时优化通过增加计算量来生成经过深思的推理步骤，从而提升模型性能。尽管现有基于搜索的策略缓解了自回归生成(myopic generation)的局限性，但庞大的搜索空间会导致过度探索(over-exploration)和利用不足(under-exploitation)。为实现探索与利用的最优平衡，我们将解码策略建模为前瞻采样(foresight sampling)，通过模拟未来步骤来获取全局最优步骤估计。基于此，我们提出新型解码策略$\phi$-Decoding。该策略通过前瞻模拟和聚类分析近似两个概率分布，从而实现对步骤价值的精确评估。通过从联合分布中采样，可筛选出最优步骤进行重点利用。为支持自适应计算资源分配，我们设计了宽度优先(in-width)和深度优先(in-depth)剪枝策略，以轻量化方案实现高效推理。在7个基准测试上的广泛实验表明，$\phi$-Decoding在性能与效率方面均显著优于现有强基线方法。进一步分析验证了该策略在不同大语言模型(LLM)上的泛化能力，以及在广泛计算预算范围内的可扩展性。代码将在https://github.com/xufangzhi/phi-Decoding开源，PyPI软件包即将发布。

## Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't
[小规模大语言模型的强化学习推理：有效方法与局限分析](https://arxiv.org/abs/2503.16219)

增强大语言模型 (LLMs) 的推理能力通常需要消耗大量计算资源和数据集，这在资源受限的场景下难以实现。本研究探索了强化学习 (RL) 对小规模大语言模型的推理能力提升效果，实验基于15亿参数的DeepSeek-R1-Distill-Qwen-1.5B模型，并在严格限制条件下完成：使用4块NVIDIA A40 GPU（每块48GB显存），训练时间不超过24小时。通过改进组相对策略优化 (Group Relative Policy Optimization, GRPO) 算法并构建精炼的高质量数学推理数据集，我们开展了三项实验来评估模型表现。结果显示推理能力显著提升——例如AMC23竞赛准确率从63%提升至80%，AIME24达到46.7%，超过o1-preview基准模型——仅消耗7000个训练样本和42美元成本，而基准模型训练需花费数千美元。但延长训练时间会导致优化不稳定性和生成长度限制等问题。这些发现证明了基于强化学习的微调对小规模大语言模型的有效性，为资源受限场景提供了一种高性价比的技术方案。我们开源了代码和数据集，揭示了性能与资源的平衡关系，为开发资源高效型推理大语言模型奠定了基础。所有资源详见https://github.com/knoveleng/open-rs。

