## InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models
[InternVL3：探索开源多模态模型的先进训练与测试阶段方案](https://arxiv.org/abs/2504.10479)

我们推出InternVL3，这是InternVL系列的重大突破，采用原生设计的多模态预训练范式。不同于将纯文本大语言模型(LLM)改造为支持视觉输入的多模态大语言模型(MLLM)的传统方法，InternVL3在单一预训练阶段中，通过多样化的多模态数据和纯文本语料库同步学习多模态与语言能力。这种统一训练范式有效解决了传统MLLM训练后流程中常见的复杂性和对齐难题。为提升性能和可扩展性，InternVL3引入了可变视觉位置编码(V2PE)以支持扩展多模态上下文，采用了监督微调(SFT)和混合偏好优化(MPO)等先进训练后技术，并实施了测试阶段扩展策略及优化的训练基础设施。大量实验评估表明，InternVL3在各类多模态任务中均展现卓越性能。其中，InternVL3-78B在MMMU基准测试中获得72.2分，在开源MLLM中创下新的SOTA记录。其性能与主流专有模型(包括ChatGPT-4o、Claude 3.5 Sonnet和Gemini 2.5 Pro)相当，同时兼具出色的纯文本处理能力。遵循开放科学原则，我们将公开训练数据和模型权重，以推动下一代MLLM的研究发展。

## Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model
[Seaweed-7B：视频生成基础模型的高效训练](https://arxiv.org/abs/2504.08685)

本技术报告提出了一种训练视频生成基础模型的低成本策略。我们展示了一个中等规模的研究模型Seaweed-7B，其参数量约70亿（7B），通过665,000 H100 GPU小时从头训练完成。尽管仅使用中等计算资源，Seaweed-7B相比参数量更大的当代视频生成模型仍展现出极具竞争力的性能。在资源受限场景下，设计决策尤为关键。本报告重点分析了提升中等规模扩散模型性能的核心设计方法。实验表明：(1) Seaweed-7B的性能可媲美甚至超越使用更多GPU资源训练的更大模型；(2) 该模型具有强大泛化能力，通过轻量微调或继续训练即可有效适配多种下游任务。项目主页：https://seaweed.video/

## PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday Home Clusters
[PRIMA.CPP：在低资源家用集群上加速70B级大语言模型推理](https://arxiv.org/abs/2504.08791)

DeepSeek R1与QwQ 32B的问世突破了前沿大语言模型(LLMs)在家用设备上的性能瓶颈。尽管消费级硬件性能持续提升且模型量化技术不断进步，现有终端方案仍依赖GPU集群、大容量内存/显存及高带宽配置，远超普通家用集群的能力范围。本文提出prima.cpp分布式推理系统，通过CPU/GPU混合计算、低内存占用、Wi-Fi传输及跨平台支持，实现在家用设备上部署70B级模型。该系统采用mmap管理模型权重，并创新性地引入带预取机制的管道环形并行(piped-ring parallelism)技术以隐藏磁盘加载延迟。通过对计算单元、通信链路、存储介质、内存管理机制及操作系统等异构资源的统一建模，实现模型层在设备CPU/GPU间的动态最优分配，从而进一步降低token延迟。针对这一NP难问题，我们提出了名为Halda的高效分配算法。在四节点家用集群上的实验表明，prima.cpp在30B以上模型中的性能优于llama.cpp、exo及dllama，同时内存压力始终低于6%。该成果使得Llama 3、DeepSeek R1、Qwen 2.5及QwQ等前沿30B-70B模型得以部署于家庭助手场景，使个人用户真正接触先进AI技术。项目代码已开源，详见https://github.com/Lizonghang/prima.cpp。

## xVerify: Efficient Answer Verifier for Reasoning Model Evaluations
[xVerify: 面向推理模型评估的高效答案验证器](https://arxiv.org/abs/2504.10481)

随着 OpenAI 推出 o1 模型，采用慢思考策略的推理模型相继问世。由于这类模型生成的响应通常包含复杂推理过程、中间推导步骤和自我反思内容，现有评估方法存在明显局限性：既难以判定大语言模型输出与参考答案的实际等价性，也无法有效从冗长复杂的响应中提取最终答案。为此，我们提出 xVerify——一种面向推理模型评估的高效答案验证系统。xVerify 展现出卓越的等价判断能力，可准确评估推理模型在各种客观题型中生成的答案与参考答案的等价性。为训练和验证 xVerify，我们构建了 VAR 数据集，通过整合多组大语言模型在不同基准数据集上生成的问答对，结合专用推理模型和针对推理评估设计的挑战性测试集。采用多轮次标注流程保证标注质量。基于 VAR 数据集，我们训练了多个不同规模的 xVerify 模型变体。在测试集和泛化集的评估实验中，所有 xVerify 模型的综合 F1 值和准确率均超过 95%。特别值得注意的是，最小参数量版本 xVerify-0.5B-I 的性能优于除 GPT-4o 外的所有基线方法，而 xVerify-3B-Ib 更是在综合性能指标上超越了 GPT-4o。这些实验结果充分验证了 xVerify 的有效性和泛化性能。

## CLIMB: CLustering-based Iterative Data Mixture Bootstrapping for Language Model Pre-training
[CLIMB：基于聚类的迭代数据混合引导方法用于大语言模型预训练](https://arxiv.org/abs/2504.13161)

预训练数据集通常采集自网络内容，缺乏明确的领域划分。例如，Common Crawl等广泛使用的数据集不包含领域标签，而人工标注数据集（如The Pile）则需耗费大量人力。尽管优化预训练数据混合能显著提升模型性能，但确定最佳混合方案仍具挑战性。为此，我们提出基于聚类的迭代数据混合引导框架CLIMB，该框架能在预训练场景下自动发现、评估并优化数据混合方案。具体实现上，CLIMB首先在语义空间中对大规模数据集进行嵌入和聚类，随后通过小型代理模型和预测器迭代搜索最优混合方案。实验表明，采用该方案训练400B token后，我们的1B参数模型性能超越当前最优的Llama-3.2-1B模型达2.0%。针对特定领域（如社会科学）优化的混合方案相比随机采样可带来5个百分点的性能提升。此外，我们发布了两个资源：包含20个聚类的1.2万亿token过滤语料库ClimbLab作为研究平台，以及专为高效预训练设计的4000亿token高性能数据集ClimbMix，后者在同等token预算下展现卓越性能。我们深入分析了最终数据混合方案，揭示了最优数据混合的特征规律。相关数据已开源：https://research.nvidia.com/labs/lpr/climb/

## Antidistillation Sampling
[抗蒸馏采样](https://arxiv.org/abs/2504.13146)

前沿模型在生成长程推理轨迹时，会无意产生具有高信息密度的 Token 序列，这些序列可能被用于模型蒸馏 (model distillation)。为应对这一潜在风险，模型所有者可能需要采用既能保持模型性能又可有效抑制蒸馏效果的采样策略。抗蒸馏采样正是为此设计的技术方案。该方法通过优化调整模型的下一个 Token 概率分布，对推理轨迹进行针对性干扰，在确保模型实用性的同时大幅降低其用于蒸馏的有效性。更多技术细节请访问：https://antidistillation.com。

## BitNet b1.58 2B4T Technical Report  
[BitNet b1.58 2B4T 技术报告](https://arxiv.org/abs/2504.12285)  

本文介绍 BitNet b1.58 2B4T，这是首个开源的、原生 1-bit 大语言模型 (LLM)，参数量级为 20 亿。该模型基于 4 万亿 token 的语料训练，并在语言理解、数学推理、编程能力和对话能力等多个基准测试中完成全面评估。实验结果表明，BitNet b1.58 2B4T 的性能与同等参数规模的主流开源全精度大语言模型相当，同时具备显著的计算效率优势，包括大幅降低的内存占用、能耗和解码延迟。为推进相关研究及实际应用，模型权重已通过 Hugging Face 开源发布，并提供支持 GPU 和 CPU 架构的推理实现代码。

## Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning
[Genius: 一种用于高级推理的通用且纯无监督的自训练框架](https://arxiv.org/abs/2504.08672)

提升大语言模型(LLM)的推理能力已成为研究热点。然而，现有的训练后技术高度依赖监督信号(如结果监督或辅助奖励模型)，存在可扩展性差和标注成本高的问题。这促使我们探索无需外部监督即可增强大语言模型推理能力的方法。我们提出了一种通用且纯无监督的自训练框架Genius。无需外部辅助，Genius通过分步搜索最优响应序列来优化大语言模型。为探索潜在步骤并筛选最优方案，Genius采用逐步前瞻重采样策略，通过模拟未来结果来采样和评估步骤价值。此外，我们意识到无监督设置会不可避免地引入固有噪声和不确定性。为此，我们提出了优势校准优化(ACO)损失函数，通过降低估计偏差来实现稳健优化。综合这些技术，Genius为基于通用查询的无监督自提升推理能力提供了创新解决方案，基于通用查询的广泛可用性，重新定义了推理扩展规律。代码将在https://github.com/xufangzhi/Genius发布。

