## Mutarjim: Advancing Bidirectional Arabic-English Translation with a Small Language Model 
[Mutarjim：基于小型语言模型的阿拉伯语-英语双向翻译技术突破](https://arxiv.org/abs/2505.17894)  

本文介绍 Mutarjim，一个专为阿拉伯语-英语双向翻译设计的紧凑型高性能语言模型。尽管当前大规模大语言模型在机器翻译等自然语言处理任务中展现出显著优势，我们发现小型模型同样具备竞争力。基于这一发现，我们在专为阿拉伯语和英语优化的 Kuwain-1.5B 语言模型基础上开发了 Mutarjim。该模型通过采用优化的两阶段训练流程和精选的高质量训练语料，在保持较小规模的同时，其性能表现超越了多个主流基准测试中的大型模型。实验数据表明，Mutarjim 的性能可与体积大 20 倍的模型相媲美，同时大幅降低了计算资源和训练成本。此外，我们提出了 Tarjama-25 新基准测试集，该数据集包含 5,000 组经过专家校验的平行句对，覆盖广泛领域，有效解决了现有阿拉伯语-英语评测数据存在的领域局限、语句过短和英语源偏置等问题，为相关研究提供了更全面均衡的评估体系。值得注意的是，Mutarjim 在 Tarjama-25 的英阿翻译任务中取得了当前最优性能，甚至超越了 GPT-4o mini 等规模显著更大的专有模型。我们将公开 Tarjama-25 数据集，以促进阿拉伯语-英语翻译系统的后续研究和评估工作。

## Shifting AI Efficiency From Model-Centric to Data-Centric Compression
[从模型中心压缩到数据中心压缩的AI效率范式转移](https://arxiv.org/abs/2505.19147)

大语言模型（LLMs）和多模态大语言模型（MLLMs）的快速发展，传统上依赖于通过参数规模从百万级扩展到千亿级来实现模型中心扩展（model-centric scaling）以提升性能。然而，随着模型规模逼近硬件极限，主要计算瓶颈已转变为长token序列自注意力（self-attention）的二次方计算成本，这一现象由超长文本上下文、高分辨率图像和长视频所驱动。在本研究报告中，**我们提出高效AI的研究重心正从模型中心压缩转向数据中心压缩**。我们认为token压缩将成为新研究前沿，通过减少模型训练和推理过程中的token数量来提升AI效率。通过系统分析，我们首先梳理了各领域长上下文AI的最新进展，建立了现有模型效率策略的统一数学框架，论证了token压缩为何能成为解决长上下文开销的关键突破。随后全面综述了token压缩的研究现状，阐明其核心优势及在不同应用场景中的显著价值。此外，我们深入探讨了当前token压缩研究面临的挑战，并展望了未来发展方向。本研究旨在为AI效率研究提供新视角，整合现有成果，并推动创新方案以应对日益增长的上下文长度对AI领域发展提出的挑战。

## TabSTAR: A Foundation Tabular Model With Semantically Target-Aware Representations
[TabSTAR: 一种具有语义目标感知表征的基础表格模型](https://arxiv.org/abs/2505.18125)

尽管深度学习在许多领域取得了显著成功，但在表格学习任务中的表现长期欠佳，这类任务至今仍以梯度提升决策树 (GBDTs) 为主导方法。然而，最新研究进展为表格基础模型的发展铺平了道路，这类模型能够利用现实世界知识并在多样化数据集上实现泛化，尤其当数据包含非结构化文本时。虽然将语言模型能力应用于表格任务已有相关探索，但现有方法大多采用静态的、与目标无关的文本表征，这限制了模型性能。我们提出 TabSTAR：一种具有语义目标感知表征的基础表格模型。该模型专为带有文本特征的表格数据迁移学习而设计，其架构不包含任何数据集特定参数。TabSTAR 通过解冻预训练文本编码器的参数，并引入目标 tokens 作为输入，使模型能够获取学习任务特定嵌入所需的上下文信息。在包含文本特征的分类任务基准测试中，TabSTAR 对中型和大型数据集均实现了最先进的性能表现。此外，其预训练阶段在数据集规模方面呈现明显的缩放规律，这为进一步提升模型性能提供了可行路径。

## The Entropy Mechanism of Reinforcement Learning for Reasoning Language Models  
[强化学习的熵机制在推理语言模型中的应用](https://arxiv.org/abs/2505.22617)  

本文旨在解决大语言模型（LLM）推理任务中扩展强化学习（RL）时面临的主要挑战——策略熵崩溃现象。在未施加熵干预的大量强化学习实验中，我们一致观察到策略熵在训练初期急剧下降的现象，而探索能力的衰减总是与策略性能的停滞同步出现。通过实证研究，我们建立了熵H与下游性能R之间的转换关系R=-a*e^H+b。这一经验规律明确表明：策略性能的提升以消耗策略熵为代价，因此当熵耗尽时性能将触及上限（H=0时R=-a+b）。这一发现说明，要实现强化学习的持续探索和计算扩展，必须对熵进行有效管理。

为此，我们从理论和实证两个维度研究了熵的动态特性。理论推导表明，策略熵的变化由动作概率与对数概率变化之间的协方差驱动，当采用类策略梯度（Policy Gradient）算法时，该协方差与其优势值成正比。实证数据验证了这一结论：协方差项与熵变化的数值完全吻合。此外，协方差项在训练过程中普遍保持正值的特性，进一步解释了策略熵单调下降的原因。

基于对熵动态机制的深入理解，我们提出了通过限制高协方差Token更新的熵控制方法。具体而言，我们开发了两种简洁高效的技术：Clip-Cov（对高协方差Token进行截断）和KL-Cov（对高协方差Token施加KL惩罚）。实验证明，这些方法能有效促进探索行为，帮助策略规避熵崩溃，从而获得更优的下游性能。

## ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows
[ScienceBoard：在真实科学工作流程中评估多模态自主智能体](https://arxiv.org/abs/2505.19897)

大语言模型 (Large Language Models, LLMs) 的影响已超越自然语言处理领域，极大地推动了跨学科研究的发展。近期，各类基于 LLM 的智能体被开发用于辅助多个领域的科学发现进程。其中，计算机操作智能体能够模拟人类与操作系统的交互方式，为自动化解决科学问题、处理科研工作流程中的常规任务开辟了新途径。

为充分挖掘这类智能体的变革潜力，我们提出 ScienceBoard 平台，其包含两项核心贡献：(i) 构建了一个真实的多领域实验环境，该环境集成专业软件并呈现动态化、可视化效果丰富的科学工作流程，智能体可通过多种接口自主交互以加速复杂科研任务与实验；(ii) 建立了包含 169 个高质量、严格验证的真实科研任务的基准测试集，涵盖生物化学、天文学和地理信息学等领域的科学发现工作流程。

基于当前最先进架构 (如 GPT-4o、Claude 3.7、UI-TARS) 的智能体评估结果显示，虽然部分任务表现良好，但其在复杂工作流程中的可靠性仍显不足，整体成功率仅为 15%。通过深入分析，我们不仅揭示了当前智能体的局限性，还提出了更有效的设计原则，为构建更强大的科研智能体指明了方向。项目代码、实验环境及基准测试集详见 https://qiushisun.github.io/ScienceBoard-Home/。

## Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers
[Paper2Poster：基于科学论文的多模态海报自动生成研究](https://arxiv.org/abs/2505.21497)

学术海报生成是科学传播领域的关键挑战，需要将包含复杂上下文关系的长篇论文内容压缩为单页视觉呈现。为解决这一问题，我们建立了首个海报生成基准测试与评估体系，通过将最新会议论文与其作者设计的海报配对，从四个维度进行评估：(i) 视觉质量——与人工设计海报的语义一致性，(ii) 文本连贯性——语言流畅程度，(iii) 综合评估——基于视觉语言模型(VLM)评分的六项美学与信息细粒度指标，(iv) PaperQuiz——通过VLM回答生成测试题来评估海报传达论文核心内容的能力。基于此基准，我们提出PosterAgent系统，采用自上而下、包含视觉反馈的多智能体架构：(a) 解析器将论文转换为结构化资源库；(b) 规划器将图文内容按阅读顺序和空间平衡原则组织为二叉树布局；(c) 绘制-评论循环通过执行渲染代码并利用VLM反馈优化每个面板，消除内容溢出并确保对齐。综合评估表明，GPT-4o生成的海报虽然初看视觉效果出色，但普遍存在文本质量不佳和PaperQuiz得分低的问题，且读者参与度是主要美学瓶颈——人工设计海报主要依靠视觉语义传递信息。我们的全开源方案(如基于Qwen-2.5系列)在几乎所有指标上都优于现有基于4o的多智能体系统，同时Token消耗量降低87%。该系统可将22页论文转换为最终可编辑的.pptx格式海报，成本仅0.005美元(约合人民币0.04元)。这些研究成果为下一代全自动海报生成模型的发展指明了方向。代码与数据集详见https://github.com/Paper2Poster/Paper2Poster。

## MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs
[MME-Reasoning：多模态大语言模型逻辑推理能力综合评测基准](https://arxiv.org/abs/2505.21327)

逻辑推理是人类智能的基础能力，也是多模态大语言模型 (MLLMs) 的核心功能。尽管多模态推理领域已取得显著进展，但由于缺乏对逻辑推理类型的明确定义以及对推理机制认知的不足，现有评测基准难以全面评估模型的推理能力。为此，我们提出 MME-Reasoning 综合评测基准，该基准通过涵盖归纳、演绎和溯因三种推理类型的问题集，系统评估 MLLMs 的推理能力。我们采用严格的数据筛选机制，确保每个问题均针对推理能力而非感知能力或知识覆盖度进行有效评估，同时扩展评测协议以支持多样化问题类型的评估。实验结果表明，当前最先进的 MLLMs 在整体逻辑推理能力评估中存在显著缺陷。即使是性能最优异的模型，在综合逻辑推理任务中表现仍不理想，且在不同推理类型间存在明显的性能差异。此外，我们对“思维模式”和基于规则的强化学习等被认为能提升推理能力的方法进行了深入分析。这些发现揭示了当前 MLLMs 在多样化逻辑推理场景中的核心局限性，为推理能力的理解与评估提供了系统性研究视角。

## QwenLong-L1: Towards Long-Context Large Reasoning Models with Reinforcement Learning
[QwenLong-L1：基于强化学习的面向长上下文大推理模型研究](https://arxiv.org/abs/2505.17667)

当前的大推理模型 (Large Reasoning Models, LRMs) 通过强化学习 (Reinforcement Learning, RL) 已展现出卓越的推理能力，但这些能力提升主要局限于短上下文推理任务。如何通过RL使LRMs有效处理长上下文输入并进行可靠推理，仍是亟待解决的核心难题。为此，我们首先建立了长上下文推理RL的理论框架，并揭示其存在的训练效率低下和优化过程失稳等关键问题。针对这些问题，我们提出QwenLong-L1框架，采用渐进式上下文扩展方法将短上下文LRMs迁移至长上下文领域。具体实现包含：1) 通过监督微调 (Supervised Fine-Tuning, SFT) 预热阶段构建强健初始策略；2) 采用基于课程学习 (Curriculum Learning) 的分阶段RL技术确保策略平稳演进；3) 引入难度感知的回溯采样策略以促进策略空间探索。在七个长上下文文档问答基准测试中，QwenLong-L1-32B模型性能显著优于OpenAI-o3-mini和Qwen3-235B-A22B等主流LRMs，达到与Claude-3.7-Sonnet-Thinking相当的水平，在现有最先进LRMs中处于领先地位。本研究为开发适用于信息密集型场景、具有稳健长上下文推理能力的实用化LRMs提供了重要技术路径。

## SWE-rebench: An Automated Pipeline for Task Collection and Decontaminated Evaluation of Software Engineering Agents
[SWE-rebench: 软件工程智能体任务收集与无污染评估的自动化流程](https://arxiv.org/abs/2505.20411)

基于大语言模型的智能体在日益增多的软件工程(SWE)任务中展现出优异潜力。然而该领域发展面临两大关键挑战：首先，高质量训练数据稀缺，特别是能反映真实SWE场景的数据——智能体需要与开发环境交互、执行代码并根据执行结果调整行为。现有数据集要么局限于单次代码生成，要么仅包含少量人工整理的交互式任务，缺乏规模性和多样性。其次，新鲜交互式SWE任务的缺失影响了快速迭代模型的评估，因为静态基准会因污染问题迅速过时。为解决这些局限，我们提出了一种新型自动化可扩展流程，能够持续从多样化GitHub仓库中提取真实交互式SWE任务。基于此流程，我们构建了公开数据集SWE-rebench，包含超过21,000个Python交互式SWE任务，适用于大规模软件工程智能体的强化学习。此外，我们利用SWE-rebench方法持续收集的新任务，构建了无污染的软件工程智能体评估基准。通过比较各类大语言模型在该基准与SWE-bench Verified上的表现，我们发现某些语言模型可能因污染问题存在性能虚高现象。

## Distilling LLM Agent into Small Models with Retrieval and Code Tools
[基于检索与代码工具的大语言模型智能体蒸馏方法](https://arxiv.org/abs/2505.17612)

大语言模型 (Large Language Models, LLMs) 在复杂推理任务中表现优异，但其高昂的计算成本限制了实际应用。近期研究通过利用教师模型生成的思维链 (Chain-of-Thought, CoT) 轨迹，尝试将推理能力蒸馏至小规模语言模型 (small Language Models, sLMs)。然而，当任务涉及罕见事实知识或需要精确计算时，由于能力限制，小模型往往会产生错误结果。本文提出智能体蒸馏框架，不仅迁移推理能力，还将基于LLM的智能体完整任务解决能力转移至具备检索与代码工具的小模型。我们通过两个互补方向改进蒸馏效果：(1) 提出"首思前缀"(first-thought prefix)提示方法，提升教师模型生成轨迹的质量；(2) 设计自洽动作生成策略，增强小智能体的测试时鲁棒性。在涵盖事实与数学领域的八项推理任务上（包括域内和域外泛化场景）的实验表明，仅0.5B、1.5B和3B参数的小模型，其性能可媲美通过CoT蒸馏微调的1.5B、3B和7B参数模型，验证了智能体蒸馏在构建实用工具型小智能体方面的潜力。代码已开源：https://github.com/Nardien/agent-distillation。

## Table-R1: Inference-Time Scaling for Table Reasoning
[Table-R1: 表格推理的推理阶段扩展](https://arxiv.org/abs/2505.23621)

本研究首次探索了表格推理任务中的推理阶段扩展方法。我们开发并评估了两种实现推理阶段扩展的后训练策略：基于前沿模型推理轨迹的知识蒸馏（Distillation）和基于可验证奖励的强化学习（RLVR）。在蒸馏方法中，我们构建了由 DeepSeek-R1 生成的大规模推理轨迹数据集，并基于此将大语言模型微调为 Table-R1-SFT 模型。在 RLVR 方法中，我们设计了任务特定的可验证奖励函数，采用 GRPO 算法训练得到 Table-R1-Zero 模型。我们在多种表格推理任务上评估了 Table-R1 系列模型，包括简短问答、事实验证和自由问答。实验结果表明，Table-R1-Zero 模型仅使用 70 亿参数规模的大语言模型，其性能就达到或超越了 GPT-4.1 和 DeepSeek-R1。该模型还展现出优异的跨领域泛化能力。通过系统的消融实验和定性分析，我们验证了指令微调、模型架构选择和跨任务泛化的有效性，同时观察到在强化学习训练过程中基础表格推理能力的涌现现象。

## Alchemist: Turning Public Text-to-Image Data into Generative Gold
[Alchemist：将公开文本到图像数据转化为生成式黄金资源](https://arxiv.org/abs/2505.19297)

预训练虽然为文生图（Text-to-Image, T2I）模型提供了广泛的世界知识，但仅凭这一点往往难以实现高审美质量和准确的文本-图像对齐。因此，监督微调（Supervised Fine-Tuning, SFT）成为提升模型性能的关键环节。然而，SFT的效果很大程度上取决于微调数据集的质量。现有公开的SFT数据集通常局限于特定领域（如动漫或特定艺术风格），而构建高质量、通用型的SFT数据集仍面临重大挑战。当前的数据筛选方法往往成本高昂，且难以识别真正具有训练价值的样本。这一问题因公开通用数据集的稀缺而更加复杂——主流模型通常依赖规模庞大、未充分公开的专有数据，这阻碍了更广泛的研究进展。

本文提出了一种创新方法：利用预训练生成模型作为高价值训练样本的评估器，构建通用型SFT数据集。基于该方法，我们构建并发布了Alchemist数据集，该数据集虽然规模精炼（仅含3,350个样本），但效果显著。实验表明，Alchemist能显著提升五个公开T2I模型的生成质量，同时保持其多样性和风格特性。此外，我们还公开了经该数据集微调后的模型权重。

## Quartet: Native FP4 Training Can Be Optimal for Large Language Models
[Quartet：原生 FP4 训练可成为大语言模型的最优解](https://arxiv.org/abs/2505.14669)

采用低精度直接训练大语言模型 (LLM) 能够通过提升吞吐量与能效来降低计算成本。为此，NVIDIA 最新 Blackwell 架构通过硬件原生支持 FP4 变体实现了超低精度运算。然而，现有 FP4 精度下的 LLM 训练算法存在显著精度损失，且往往需要依赖混合精度补偿策略。本文研究了硬件支持的 FP4 训练，提出了一种新型端到端 FP4 训练方法，该方法使所有主要计算（包括线性层）均保持低精度运行。基于对 Llama 架构模型的全面评估，我们发现了新的低精度缩放规律，可量化不同位宽与训练配置间的性能权衡关系。基于此研究，我们开发出在精度-计算效率维度达到最优的技术 Quartet。通过为 Blackwell 架构优化的定制 CUDA 内核实现，Quartet 证实了纯 FP4 训练方案在性能上足以比肩 FP16 半精度与 FP8 训练方案。代码已开源：https://github.com/IST-DASLab/Quartet。

## R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing
[R2R：基于小-大模型 Token 路由的高效发散推理路径导航](https://arxiv.org/abs/2505.21600)

大语言模型 (LLMs) 虽具备强大的推理能力，却伴随着高昂的推理成本，这给实际部署带来了巨大挑战。尽管蒸馏后的小语言模型 (SLMs) 效率显著提升，但其性能因无法复现大语言模型的推理路径而受限。研究发现，实际上仅有少量 Token 会真正引发大语言模型与小语言模型间的推理路径分歧。大多数生成 Token 要么完全一致，要么仅存在中性差异（如缩写或表达方式的细微差别）。基于此发现，我们提出 **路径路由 (R2R)** 神经 Token 路由方法，该方法仅针对关键路径分歧 Token 调用大语言模型，而将大部分 Token 生成任务交由小语言模型处理。我们还开发了自动化数据生成流程，用于识别分歧 Token 并生成 Token 级路由标签以训练轻量级路由器。将 R2R 应用于 DeepSeek 系列的 R1-1.5B 和 R1-32B 模型组合后，在数学、编程和问答等复杂基准测试中，仅激活平均 5.6B 参数的 R2R 以 1.6 倍优势超越 R1-7B 的平均准确率，甚至优于 R1-14B 模型。与 R1-32B 相比，在保持相当性能的同时实现了 2.8 倍的实际运行加速，显著推进了推理时扩展效率的帕累托前沿。项目代码已开源：https://github.com/thu-nics/R2R。

## OmniConsistency: Learning Style-Agnostic Consistency from Paired Stylization Data
[OmniConsistency：从成对风格化数据中学习风格无关的一致性](https://arxiv.org/abs/2505.18445)

扩散模型 (Diffusion models) 显著推动了图像风格化技术的发展，但仍面临两大核心挑战：(1) 在复杂场景中保持风格化的一致性，特别是身份特征、构图结构和细节表现；(2) 在使用风格低秩适配器 (LoRAs, Low-Rank Adaptations) 的图像到图像 (image-to-image) 流程中避免风格退化。GPT-4o 展现出的卓越风格化一致性，凸显了开源方法与专有模型之间的性能差距。为弥合这一差距，我们提出 \textbf{OmniConsistency}——一个基于大规模扩散 Transformer (DiTs, Diffusion Transformers) 的通用一致性插件。该方案的主要贡献包括：(1) 基于对齐图像对训练的上下文一致性学习框架，可实现鲁棒泛化；(2) 采用两阶段渐进学习策略，通过解耦风格学习与一致性保持来缓解风格退化；(3) 完全即插即用的设计，兼容 Flux 框架下的各类风格 LoRAs。大量实验表明，OmniConsistency 能显著提升视觉连贯性和美学效果，其性能已达到与当前最先进 (state-of-the-art) 商业模型 GPT-4o 相当的水平。

## Reasoning Model is Stubborn: Diagnosing Instruction Overriding in Reasoning Models
[推理模型的顽固性：诊断指令覆盖行为](https://arxiv.org/abs/2505.17225)

大语言模型在处理复杂长链推理任务时展现出卓越能力，但普遍存在过度依赖固有推理模式的问题，这种现象我们称为\textit{推理刚性}。即便面对用户明确指令，模型仍会频繁无视既定条件，习惯性地沿用固有推理路径，最终导致错误结论。这种行为在数学和逻辑谜题等需要严格遵循约束条件的领域构成严峻挑战。为系统研究这一尚未被充分探索的现象，我们构建了一个专家精心设计的诊断数据集\dataset{}。该数据集包含对现有数学基准（AIME和MATH500）的特制修改版本，以及经过专门重构、要求突破常规推理策略的经典谜题。基于此数据集，我们识别出模型陷入固有推理模式时表现出的系统性偏差模式，并将其归纳为三类典型特征：(i) 解释过载 (Interpretation Overload)，(ii) 输入质疑 (Input Distrust)，以及(iii) 指令选择性关注 (Partial Instruction Attention)，这些特征均会导致模型忽视或曲解给定指令。我们公开此诊断数据集以推动语言模型推理刚性缓解技术的相关研究。

## BizFinBench: A Business-Driven Real-World Financial Benchmark for Evaluating LLMs  
[BizFinBench：业务导向的真实金融场景大语言模型评估基准](https://arxiv.org/abs/2505.19457)  

大语言模型在通用任务中表现优异，但在金融、法律和医疗等强逻辑、高精度领域的可靠性评估仍具挑战。为此，我们提出首个面向真实金融应用的大语言模型评估基准BizFinBench，包含6,781条高质量标注的中文查询，覆盖数值计算、逻辑推理、信息抽取、预测识别和知识问答五个维度，并进一步细分为九个精细类别。该基准采用主客观双重评价指标，并创新性地提出IteraJudge方法，有效降低大语言模型作为评估者时的客观指标偏差。我们对25个专有和开源模型进行了系统评测，实验表明：(1) 数值计算任务中，Claude-3.5-Sonnet (63.18) 和 DeepSeek-R1 (64.04) 领先，Qwen2.5-VL-3B (15.92) 等小模型显著落后；(2) 逻辑推理任务中，专有模型优势明显（ChatGPT-o3: 83.58, Gemini-2.0-Flash: 81.15），开源模型最大差距达19.49分；(3) 信息抽取任务性能离散度最大，DeepSeek-R1 (71.46) 与 Qwen3-1.7B (11.23) 差异显著；(4) 预测识别任务性能波动最小，顶级模型得分集中在39.16-50.00区间。研究发现当前大语言模型可较好处理常规金融查询，但在需要跨概念推理的复杂场景中存在明显不足。BizFinBench为相关研究提供了严格匹配业务需求的评估基准，代码与数据集详见 https://github.com/HiThink-Research/BizFinBench。

## Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence  
[Spatial-MLLM：增强多模态大语言模型的视觉空间智能能力](https://arxiv.org/abs/2505.23747)  

多模态大语言模型 (Multimodal Large Language Models, MLLMs) 的最新进展显著提升了其在二维视觉任务上的性能，但其空间智能能力的提升仍面临挑战。现有三维多模态大语言模型通常需要依赖额外的三维或2.5维数据来实现空间感知，这限制了其在仅有二维输入（如图像或视频）场景中的应用。本文提出 Spatial-MLLM，一种基于纯二维观测的视觉空间推理新框架。与传统视频多模态大语言模型采用基于 CLIP 的视觉编码器（专为语义理解优化）不同，我们的核心创新在于利用前馈视觉几何基础模型中的强结构先验。具体而言，我们设计了双编码器架构：预训练的二维视觉编码器用于提取语义特征，以及基于视觉几何模型骨干网络初始化的空间编码器用于提取三维结构特征。通过连接器将两类特征融合为统一的视觉 Token，从而增强空间理解能力。此外，我们在推理阶段提出了空间感知的帧采样策略，从视频序列中筛选具有空间信息量的关键帧，确保在有限 Token 长度下模型仍能聚焦于对空间推理至关重要的帧数据。除架构创新外，我们还构建了 Spatial-MLLM-120k 数据集，并采用监督微调和 GRPO 方法进行模型训练。多组真实数据集实验表明，我们的 Spatial-MLLM 在各类视觉空间理解与推理任务中均达到了最先进的性能水平。项目页面：https://diankun-wu.github.io/Spatial-MLLM/。

## The Climb Carves Wisdom Deeper Than the Summit: On the Noisy Rewards in Learning to Reason
[攀登之路比巅峰更铸智慧：论推理学习中的噪声奖励机制](https://arxiv.org/abs/2505.22653)

近期针对大语言模型 (LLM) 通过强化学习 (RL) 进行推理能力训练的研究，主要集中在可精确验证和奖励的任务（如数学解题）上。与此不同，本研究探讨了奖励噪声的影响——这是基于奖励模型对 LLM 进行实际训练时更需关注的现实因素。我们发现 LLM 对高强度奖励噪声具有显著鲁棒性。例如，在数学任务中人为反转 40% 的奖励函数输出，仍能使 Qwen-2.5-7B 模型快速收敛，其数学任务准确率从 5% 提升至 72%，而使用无噪声奖励训练的模型准确率为 75%。令人惊讶的是，仅对关键推理短语（即推理模式奖励，RPR）的出现给予奖励（如"首先，我需要"这类表述），无需验证答案正确性，模型就能达到与严格验证的精确奖励训练相当的性能峰值（Qwen-2.5-7B 准确率超 70%）。基于推理过程比结果更重要的认知，我们将 RPR 与噪声奖励模型结合。RPR 能有效校准噪声奖励模型，减少误判并提升 LLM 在开放式任务中的表现。这些发现不仅凸显了预训练阶段夯实模型基础能力的关键价值，也为后续训练技术的改进提供了新思路。代码和脚本详见 https://github.com/trestad/Noisy-Rewards-in-Learning-to-Reason。

## SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning Logical Reasoning and Beyond
[SynLogic：面向逻辑推理及其他领域的大规模可验证推理数据合成](https://arxiv.org/abs/2505.19641)

OpenAI-o1 和 DeepSeek-R1 等最新研究成果表明，强化学习 (Reinforcement Learning, RL) 能有效增强大语言模型 (Large Language Models, LLMs) 的推理能力。当前开源社区的研究主要集中在数学和编程领域，而开发通用推理能力的方法与资源仍存在研究空白。这一现状部分源于难以获取适合 RL 训练的多样化且可验证的推理数据。我们认为逻辑推理是发展通用推理能力的关键基础，因为逻辑构成了推理的基本单元。本研究提出 SynLogic 框架及数据集，通过可扩展的数据合成方法生成涵盖 35 种逻辑推理任务的多样化数据。SynLogic 支持通过可调节的难度和数量参数精确控制数据生成过程，且所有生成样本均可通过简单规则验证，这使其成为支持可验证奖励机制的 RL 训练的理想选择。基于 7B 和 32B 模型的实验表明：在 SynLogic 数据上进行 RL 训练能显著提升模型性能，其逻辑推理能力在开源数据集中达到最优水平，在 BBEH 基准上以 6 分优势超越 DeepSeek-R1-Distill-Qwen-32B。此外，将 SynLogic 数据与数学、编程任务混合训练不仅能提升这些领域的训练效率，还可显著增强模型的推理泛化能力。值得注意的是，我们的混合训练模型在多项基准测试中的表现均优于 DeepSeek-R1-Zero-Qwen-32B。这些成果表明 SynLogic 是提升 LLMs 广义推理能力的宝贵资源。我们已在 https://github.com/MiniMax-AI/SynLogic 开源数据合成工具链及完整数据集。

## Exploring the Latent Capacity of LLMs for One-Step Text Generation  
[探索大语言模型在单步文本生成中的潜在能力](https://arxiv.org/abs/2505.21189)  

最新研究表明，大语言模型 (LLM) 仅需一个经过特殊训练的输入嵌入，即可通过自回归生成重建长达数千 token 的文本。本文探讨了非自回归条件下实现此类重建的可能性。我们发现，冻结参数的 LLM 在仅输入两个学习所得嵌入时，通过单次前向计算即可生成数百个准确 token。这一现象揭示了 LLM 一项未被充分探索的惊人能力——无需迭代解码的多 token 生成。我们分析了这些嵌入的行为特性，解析其编码的信息类型，并通过实证表明：虽然这些表示对给定文本不具备唯一性，但会在嵌入空间中形成连通且局部的区域——该特性暗示了学习专用空间编码器的潜在价值。

## One RL to See Them All: Visual Triple Unified Reinforcement Learning
[全能视觉强化学习：视觉三元统一强化学习系统](https://arxiv.org/abs/2505.18129)

强化学习 (RL) 显著提升了视觉语言模型 (VLMs) 的推理能力。然而，RL 在非推理任务中的应用仍待探索，特别是对于目标检测和定位等高感知需求任务。我们提出 V-Triune，一个视觉三元统一强化学习系统，使 VLMs 能在单一训练流程中同步学习视觉推理与感知任务。V-Triune 包含三个互补组件：样本数据格式化 (统一多样化任务输入)、验证器奖励计算 (通过专用验证器提供定制奖励) 以及源指标监控 (数据源级问题诊断)。我们创新性地提出动态 IoU 奖励，为 V-Triune 处理的感知任务提供自适应、渐进且明确的反馈。该方法基于通用 RL 训练框架实现，采用开源 7B 和 32B 骨干模型。最终模型 Orsta (One RL to See Them All) 在推理和感知任务上均表现持续提升。这种广泛能力源于其多样化训练数据集，涵盖四大视觉推理任务 (数学、谜题、图表和科学) 和四大视觉感知任务 (定位、检测、计数和 OCR)。实验表明，Orsta 在 MEGA-Bench Core 基准上取得显著提升，各 7B 和 32B 模型变体的性能增益区间为 +2.1 至 +14.1，且该优势能泛化至多种下游任务。这些结果验证了我们统一 RL 方法对 VLMs 的有效性与可扩展性。V-Triune 系统及 Orsta 模型已开源：https://github.com/MiniMax-AI。

## VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos
[VF-Eval：多模态大语言模型在AIGC视频反馈生成中的评估](https://arxiv.org/abs/2505.23693)

近年来，多模态大语言模型（MLLMs）在视频问答任务中得到了广泛研究。然而，现有评估主要集中于自然视频，而忽略了合成视频（如AI生成内容，AIGC）。同时，尽管部分视频生成研究依赖MLLMs评估生成视频质量，但MLLMs在解析AIGC视频方面的能力仍缺乏深入探索。为此，我们提出新基准VF-Eval，通过四项任务（连贯性验证、错误识别、错误类型检测和推理评估）全面评估MLLMs在AIGC视频上的能力。我们对13个前沿MLLMs进行了评估，发现即使性能最优的GPT-4.1模型也难以在所有任务中保持稳定表现，这体现了本基准的挑战性。此外，为探究VF-Eval在视频生成改进中的实际应用，我们开展了RePrompt实验，结果表明使MLLMs更贴近人类反馈有助于提升视频生成质量。

## OpenS2V-Nexus: A Detailed Benchmark and Million-Scale Dataset for Subject-to-Video Generation
[OpenS2V-Nexus：面向主体到视频生成的详细基准与百万规模数据集](https://arxiv.org/abs/2505.20292)

主体到视频（Subject-to-Video，S2V）生成技术旨在创建能精准融合参考内容的视频，为视频制作提供更高的灵活性。为构建S2V生成的研究基础设施，我们提出OpenS2V-Nexus框架，包含：(i) OpenS2V-Eval细粒度评估基准；(ii) OpenS2V-5M百万规模数据集。与现有基于VBench的S2V基准不同（后者侧重全局性粗粒度评估），OpenS2V-Eval专注于评估模型生成主体一致性视频的能力，要求视频具备自然的主体外观和身份一致性。为此，OpenS2V-Eval从7个主要S2V类别中精选180个提示词，同时包含真实数据与合成数据。此外，为精准对齐人类偏好与评估标准，我们提出NexusScore、NaturalScore和GmeScore三个自动化评估指标，分别量化生成视频的主体一致性、自然度和文本关联度。基于该框架，我们对16个代表性S2V模型进行全面评估，系统分析其在不同内容场景下的优劣。同时，我们构建了首个开源的大规模S2V数据集OpenS2V-5M，包含500万组720P高清的主体-文本-视频三元组。通过：(1) 主体分割与跨视频关联分析构建配对信息；(2) 基于原始帧使用GPT-Image-1合成多视角表征，我们确保了数据集的主体信息多样性。OpenS2V-Nexus为未来S2V生成研究提供了强大的基础设施支持。

## Don't Overthink it. Preferring Shorter Thinking Chains for Improved LLM Reasoning
[无需过度思考：采用更短思考链提升大语言模型推理能力](https://arxiv.org/abs/2505.17813)

当前大语言模型(LLMs)的推理能力高度依赖通过扩展测试时计算(test-time compute)来生成冗长的"思考"链。尽管这种方法取得了显著效果，但伴随着巨大的计算开销和推理延迟。本研究质疑了"思考链越长则推理能力越强"的固有认知。我们首先证实：针对单个问题，较短的推理链获得正确答案的概率显著更高——相比同一问题中最长的思考链，准确率最高可提升34.5%。基于此发现，我们提出新型推理方法short-m@k：并行执行k个独立生成过程，当最先完成的m个思考过程终止时，通过多数投票机制确定最终答案。基础版short-1@k在低计算量场景下性能与标准多数投票相当甚至更优，同时减少高达40%的思考token消耗；进阶版short-3@k虽效率略低，但在所有计算预算下均稳定优于多数投票，且实际耗时显著降低(最高减少33%)。受此启发，我们分别采用短链、长链和随机链对大语言模型进行微调，结果表明基于短链的训练能获得更优性能。本研究建议重新审视当前大语言模型推理中的计算资源配置策略——更长的思考过程未必带来性能提升，反而可能产生反效果。

## Skywork Open Reasoner 1 Technical Report
[Skywork Open Reasoner 1 技术报告](https://arxiv.org/abs/2505.22312)  

DeepSeek-R1 的成功验证了强化学习 (Reinforcement Learning, RL) 在增强大语言模型 (Large Language Models, LLMs) 推理能力中的关键作用。本研究提出 Skywork-OR1，这是一种面向思维链 (Chain-of-Thought, CoT) 模型的高效可扩展 RL 实现方案。基于 DeepSeek-R1-Distill 模型系列，我们的 RL 方法实现了显著性能提升：在 AIME24、AIME25 和 LiveCodeBench 基准上，32B 模型的平均准确率从 57.8% 提升至 72.8%（绝对提升 15.0 个百分点），7B 模型从 43.6% 提升至 57.5%（绝对提升 13.9 个百分点）。Skywork-OR1-32B 在 AIME24 和 AIME25 基准上超越 DeepSeek-R1 和 Qwen3-32B，同时在 LiveCodeBench 上达到相当水平。Skywork-OR1-7B 和 Skywork-OR1-Math-7B 在同等规模模型中展现出具有竞争力的推理性能。我们通过全面的消融实验验证了训练流程核心组件的有效性，并系统研究了熵塌缩现象，识别出影响熵动态的关键因素，证明缓解过早熵塌缩对提升测试性能至关重要。为促进社区研究，我们完整开源了模型权重、训练代码及训练数据集。

## Sherlock: Self-Correcting Reasoning in Vision-Language Models
[Sherlock：视觉语言模型的自校正推理框架](https://arxiv.org/abs/2505.22651)

具备推理能力的视觉语言模型（Vision-Language Models, VLMs）在复杂多模态任务中表现出色，但仍存在三个主要局限：推理过程容错性差、依赖海量标注数据或精准验证模块、领域泛化能力不足。为解决这些问题，我们提出采用自校正机制来增强 VLMs 的推理能力。通过系统分析现有 VLMs 的自校正缺陷，我们设计了 Sherlock 自校正训练框架，其核心创新包括：轨迹层面的自校正优化目标、基于视觉扰动的偏好数据生成策略，以及动态调整的 $\beta$ 偏好调优参数。该框架仅需 2 万条随机标注样本即可使模型获得自校正能力，并实现无监督的持续优化。基于 Llama3.2-Vision-11B 实现的 Sherlock 在八大基准测试中取得突破性进展：直接推理准确率 64.1，自校正后提升至 65.4，显著优于 LLaVA-CoT（63.2）、Mulberry（63.9）和 LlamaV-o1（63.4）等对比模型，且训练数据用量减少 80% 以上。

## PhyX: Does Your Model Have the "Wits" for Physical Reasoning?
[PhyX: 你的模型具备物理推理的"智慧"吗？](https://arxiv.org/abs/2505.15929)

现有基准测试未能捕捉智能的一个关键方面——物理推理：这种需要整合领域知识、符号推理和现实约束理解的综合能力。为填补这一空白，我们推出PhyX——首个面向视觉场景物理推理能力评估的大规模基准。PhyX包含3000个精心设计的跨模态问题，覆盖6种推理类型、25个子领域及6大核心物理领域：热力学、电磁学、力学、现代物理、光学以及波与声学。

在全面评估中，最先进模型在物理推理任务上表现欠佳。GPT-4o、Claude3.7-Sonnet和GPT-o4-mini的准确率分别仅为32.5%、42.2%和45.8%，与人类专家相比存在超过29%的性能差距。分析表明当前模型存在关键缺陷：过度依赖记忆中的学科知识、对数学公式的严重依赖，以及仅进行浅层视觉模式匹配而非建立真正的物理理解机制。

我们通过细粒度统计、典型案例分析和多重评估范式展开深入研究。为确保结果可复现，基于VLMEvalKit等通用工具包构建了兼容性评估协议，支持一键式测试。更多信息详见项目主页：https://phyx-bench.github.io/。

## PATS: Process-Level Adaptive Thinking Mode Switching
[PATS：过程级自适应思维模式切换](https://arxiv.org/abs/2505.19250)

当前大语言模型 (LLMs) 通常采用固定推理策略处理所有问题，无论问题简单或复杂，均不考虑其难度差异。这种对任务复杂度及推理过程变化的忽视，导致模型性能与效率失衡。现有方法尝试通过免训练的快速-慢速思维系统切换来处理不同难度问题，但其方案级策略调整粒度较粗。为此，我们提出新型推理范式：过程级自适应思维模式切换 (PATS)，使大语言模型能依据各步骤难度动态调整推理策略，优化准确率与计算效率的平衡。该方法将过程奖励模型 (PRMs) 与波束搜索 (Beam Search) 相结合，引入渐进式模式切换和错误步骤惩罚机制。在多个数学基准测试中，该方法在保持合理 Token 消耗的同时实现了高准确率。本研究揭示了过程级难度感知推理策略自适应的重要性，为大语言模型高效推理提供了新思路。

